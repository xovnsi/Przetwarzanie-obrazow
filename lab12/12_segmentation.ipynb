{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "uVI8Y7VtrR3r"
   },
   "source": [
    "# Segmentacja obrazów\n",
    "\n",
    "## Cel ćwiczenia\n",
    "- zapoznanie z metodami segmentacji obrazów:\n",
    "    - segmentacją przez rozrost,\n",
    "    - segmentacją przez podział i scalanie.\n",
    "- zadanie domowe: segmentacja z wykorzystaniem wododziałów morfologicznych.\n",
    "\n",
    "## Wstęp\n",
    "\n",
    "W ramach dotychczas wykonanych ćwiczeń poznaliśmy segmentację z wykorzystaniem binaryzacji (progowania) - tj. na podstawie jasności (koloru) poszczególnych pikseli.\n",
    "Wykonaliśmy dwa warianty metody: globalny i lokalny oraz przetestowaliśmy różne podejścia do automatycznego wyznaczania progu bianryzacji (iteracyjne oraz Otsu).\n",
    "\n",
    "Ponadto poznaliśmy możliwość segmentacji na podstawie krawędzi z wykorzystaniem transformaty Hough'a.\n",
    "\n",
    "W tym ćwiczeniu poznamy dwie inne metody podziału obrazu na fragmenty:\n",
    "-  segmentację przez rozrost obszaru (ang. *region growing*),\n",
    "- segmentację przez podział i scalanie (ang. *split and merge*)."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Podstawy\n",
    "\n",
    "Niech $R$ oznacza obszar równy całemu analizowanemu obrazowi.\n",
    "Segmentację możemy uznać za proces podziału $R$ na $n$ podobszarów $R_1,R_2,...,R_n$ takich że:\n",
    "1. $\\cup_{i=1}^n R_i = R$\n",
    "- $R_i$ - składa się z połączonych ze sobą pikseli,\n",
    "- $R_i \\cap R_j = \\varnothing $ dla wszystkich $i$ i $j$,$ i \\neq j$,\n",
    "- $Q(R_i) = TRUE$ dla $i = 1,2,...n$\n",
    "- $ Q(R_i \\cup R_j) = FALSE$ dla każdych sąsiednich $R_i$ i $R_j$.\n",
    "\n",
    "gdzie: symbole $\\cup$ i $\\cap$ oznaczają odpowiednio sumę i iloczyn zbiorów, a $Q$ jest pewnym predykatem.\n",
    "\n",
    "Punkt *1* oznacza, że segmentacja musi być kompletna tj. każdy piksel powinien zostać przyporządkowany do jakiegoś zbioru.\n",
    "\n",
    "Punkt *2* oznacza, że piksele w ramach jednego podobszaru muszą być ze sobą połączone (na zasadzie sąsiedztwa 4 lub 8 punktowego).\n",
    "\n",
    "Punkt *3* oznacza, że dowolne różne podobszary muszą być rozłączne.\n",
    "\n",
    "Punkt *4* oznacza, że wszystkie piksele będące w ramach jednego podobszaru muszą spełniać pewną własność. Przykładowo może to być ten sam lub podobny odcień szarości.\n",
    "\n",
    "Punkt *5* oznacza, że dwa sąsiednie podobszary muszą być różne w sensie predykatu Q (inaczej powinny zostać uznane za ten sam podobszar)."
   ],
   "metadata": {
    "collapsed": false,
    "id": "97c_ALaNrR32"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Segmentacja przez rozrost obszaru\n",
    "\n",
    "Pomysł jest następujący.\n",
    "Wybieramy (jak ? - o tym później) piksele startowe (ang. *seed*) i od nich zaczynamy segmentację.\n",
    "Odbywa się ona na zasadzie sprawdzania czy sąsiednie piksele (sąsiedztwo 4 lub 8 punktowe) są podobne do centralnego pod względem jakieś cechy (predykatu $Q$).\n",
    "Jeśli tak to oznaczane są jako należące do tej samej klasy co piksel centralny.\n",
    "Ponadto stają się one kolejnymi punktami startowymi metody.\n",
    "Zatem procedura ma charakter rekurencyjny.\n",
    "\n",
    "Wybór punktów startowych może być podyktowany charakterem problemu (przykładowo wiemy gdzie na pewno zaczynają się obiekty).\n",
    "W ogólnym przypadku trzeba założyć, że pikselem startowym może być każdy piksel, co oczywiście wpływa na złożoność metody.\n",
    "\n",
    "Kolejnym problemem jest wybór kryterium stopu tj. kiedy nasza procedura rekurencyjna ma się zakończyć.\n",
    "Dla danego podobszaru będzie to moment, kiedy nie istnieją już piksele, które można do  niego dołączyć.\n",
    "\n",
    "Warto w tym miejscu zwrócić uwagę, że stosowanie ''sztywnego'' warunku - np. różnica jasności pomiędzy pikselem centralnym, a analizowanym jest mniejsza niż 5 - może często dać niepożądane wyniki, gdyż nie uwzględnia pewnych lokalnych właściwości.\n",
    "Przykładowo, może się okazać, że jeśli na obrazie występuje niewielki gradient to za należące do tego samego obszaru uznane zostaną piksele o zupełnie różnych jasnościach.\n",
    "Możliwa jest też sytuacja odwrotna.\n",
    "Duże zróżnicowanie wartości na obrazie spowoduje zbyt duże ''poszarpanie'' wykrytych obszarów.\n",
    "\n",
    "Jednym z możliwych rozwiązań jest uzależnienie kryterium podobieństwa (predykatu $Q$) od własności obrazu np. średniej jasności w obrębie danego obszaru.\n",
    "Można również dodać inne kryteria np. kształt podobszaru itp.\n",
    "\n",
    "Uwaga. Pojęcie segmentacja przez rozrost to pewna **koncepcja** podejścia do segmentacji, a nie konkretna metoda.\n",
    "Na etapie projektowania algorytmu należy skupić się na konstrukcji kryterium podobieństwa (tj. co i jak ma być ze sobą porównywane) oraz ewentualnym uzupełnianiu metody o dodatkowe kryteria.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "id": "hNHpDTGMrR38"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Zadanie: zaprojektować system segmentacji wybranej struktury na obrazie MRI (np. stawu kolanowego).\n",
    "Punkt startowy wyznaczany będzie ''ręcznie'' (poprzez kliknięcie na obrazie).\n",
    "\n",
    "1. Wczytaj obraz *knee.png* (w skali szarości) - MRI stawu kolanowego. Wyświetl go. Załóżmy, że chcemy dokonać segmentacji górnej kości. Przyjęliśmy, że punkt startowy metody wyznaczany będzie w sposób ręczny. Przykładowy punkt startowy:\n",
    "```\n",
    "X = 290\n",
    "Y = 259\n",
    "```\n",
    "\n",
    "2. Metodę zaimplementujemy z wykorzystaniem stosu.\n",
    "   Uwaga. Podany poniżej opis jest tylko jedną z możliwych realizacji (niekoniecznie najlepszą).\n",
    "   Na początek tworzymy dwie macierze o rozmiarach takich jak analizowany obraz.\n",
    "   W jednej będziemy zapisywać odwiedzone lokalizacje (`visited` - typ *boolean*), a w drugiej rezultaty segmentacji (`segmented`).\n",
    "   Obie macierze tworzymy wypełnione zerami (funkcja `np.zeros`).\n",
    "   Tworzymy też stos - w Python to po prostu ''pusta lista''.\n",
    "\n",
    "3. W pierwszym kroku metody na stos (`stack.append`) odkładamy współrzędne wybranego przez użytkowania piksela.\n",
    "   Oznaczamy go również jako odwiedzony (macierz *visited*) i zaliczony do obiektu (macierz *segmented*).\n",
    "\n",
    "4. Pozostałe działanie odbywać się będzie w pętli `while`, której warunkiem stopu jest brak elementów na stosie (`len(stack)>0`).\n",
    " W iteracji należy pobrać współrzędne piksela ze stosu.\n",
    "  Następnie sprawdzamy, czy dla tego piksela można określić kontekst o rozmiarze $ 3 \\times 3$ tj. czy ma wszystkich sąsiadów.\n",
    "  Uwaga. Przyjmujemy tutaj uproszczenie - nie segmentujemy brzegu obrazka (ramki o szerokości 1 piksela).\n",
    "\n",
    "5. W kolejnym kroku rozpisujemy pętlę po otoczeniu $3 \\times 3$ (x2 `for`).\n",
    "   Wewnątrz obliczamy odległość pomiędzy pikselem centralnym, a każdym z kontekstu.\n",
    "   Przyjmijmy, że będzie to moduł z różnicy jasności.\n",
    "   Jeśli wartość modułu będzie mniejsza od zdefiniowanego progu (proszę przyjąć jako początkową wartość 4) oraz rozpatrywany piksel nie był wcześniej odwiedzany to oznaczamy go jako należący do obiektu oraz jego współrzędne ''odkładamy'' na stosie.\n",
    "   Uwaga. Pierwsza część warunku logicznego to nasz predykat Q.\n",
    "   Za piksele podobne uznajemy takie, których różnica w jasności jest mniejsza niż zadany próg.\n",
    "   Niezależnie od wyniku testu oznaczamy piksel jako odwiedzony (żeby wielokrotnie nie analizować tych samych lokalizacji).\n",
    "\n",
    "6. Poza pętlą `while` proszę wyświetlić rezultat segmentacji.\n",
    "   Czy wyniki są poprawne ?\n",
    "   Proszę poeksperymentować z wartością progu."
   ],
   "metadata": {
    "collapsed": false,
    "id": "mUmWxkkQrR4A"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/vision-agh/poc_sw/master/12_Segmentation/'\n",
    "\n",
    "fileNames = [\"knee.png\", \"umbrella.png\"]\n",
    "for fileName in fileNames:\n",
    "  if not os.path.exists(fileName):\n",
    "      r = requests.get(url + fileName, allow_redirects=True)\n",
    "      open(fileName, 'wb').write(r.content)\n",
    "\n",
    "knee = cv2.imread(\"knee.png\", 0)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "hJ2Ycg_WrR4F"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.imshow(knee, \"gray\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def segmentation(img, threshold=4):\n",
    "    X, Y = img.shape\n",
    "    visited = np.zeros((X, Y))\n",
    "    segmented = np.zeros((X, Y))\n",
    "    stack = []\n",
    "\n",
    "    x0 = 290\n",
    "    y0 = 259\n",
    "\n",
    "    stack.append([x0, y0])\n",
    "    visited[x0, y0] = True\n",
    "    segmented[x0, y0] = img[x0, y0]\n",
    "\n",
    "    while len(stack) > 0:\n",
    "        row, col = stack.pop()\n",
    "        if row + 1 < X and col + 1 < Y and row - 1 >= 0 and col - 1 >= 0:\n",
    "            for i in range(row - 1, row + 2):\n",
    "                for j in range(col - 1, col + 2):\n",
    "                    dist = abs(img[row, col].astype(\"int\") - img[i, j].astype(\"int\"))\n",
    "                    if dist < threshold and not visited[i, j]:\n",
    "                       stack.append([i, j])\n",
    "                    segmented[i, j] = img[row, col]\n",
    "                    visited[i, j] = True\n",
    "    return segmented"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result = segmentation(knee)\n",
    "plt.imshow(result, cmap=\"gray\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Powyższy przykład ukazuje wspomniany wcześniej problem z ''globalnym'' podejściem do predykatu Q.\n",
    "  Jeśli próg będzie mały, to wyznaczymy jedynie niewielki fragment kości.\n",
    "  Natomiast zwiększenie progu skutkuje segmentacją nadmiarową.\n",
    "  Mówiąc kolokwialnie, na obrazie znajdzie się ''ścieżka'' po której możliwe jest przejście od obszaru jasnego do ciemnego nie ''łamiąc'' progu odległości pomiędzy sąsiednimi pikselami.\n",
    "\n",
    "2. Aby zaradzić powyższemu problemowi, można za kryterium podobieństwa przyjąć, nie różnicę jasności względem piksela centralnego, a od globalnie wyznaczonego i aktualizowanego progu.\n",
    "  W najprostszym przypadku może to być średnia jasność w wyznaczonym obszarze.\n",
    "  W celu implementacji mechanizmu wystarczy dodać dwie zmienne: średnią ($mV$) oraz licznik pikseli uznanych za należące do obiektu ($nS$).\n",
    "  Przy każdym zdjęciu ze stosu licznik jest zwiększany o 1.\n",
    "  Aktualizacja średniej następuje na podstawie równania:\n",
    "  \\begin{equation}\n",
    "  mV_{n} = \\frac{mV_{nS-1} (nS - 1) + I}{nS}\n",
    "  \\end{equation}\n",
    "  Następnie wystarczy tylko zmienić sposób obliczania odległości - zamienić piksel centralny na wartość średnią.\n",
    "  Proszę spróbować jak działa metodą z taką modyfikacją.\n",
    "  Proszę się liczyć z koniecznością zwiększenia progu (nawet dość znaczną).\n",
    "\n",
    "3. Poprawić działanie metody może również dodanie filtracji uśredniającej np. filtrem Gaussa."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "z66H-4VyrR4I"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def second_segmentation(img, threshold=4):\n",
    "    X, Y = img.shape\n",
    "    visited = np.zeros((X, Y))\n",
    "    segmented = np.zeros((X, Y))\n",
    "    stack = []\n",
    "    nS = 0\n",
    "\n",
    "    x0 = 290\n",
    "    y0 = 259\n",
    "\n",
    "    mean = img[x0, y0]\n",
    "    stack.append([x0, y0])\n",
    "    visited[x0, y0] = True\n",
    "    segmented[x0, y0] = img[x0, y0]\n",
    "\n",
    "    while len(stack) > 0:\n",
    "        row, col = stack.pop()\n",
    "        nS += 1\n",
    "        mean = ((mean * (nS - 1)) + img[row, col]) / nS\n",
    "\n",
    "        if row + 1 < X and col + 1 < Y and row - 1 >= 0 and col - 1 >= 0:\n",
    "            for i in range(row - 1, row + 2):\n",
    "                for j in range(col - 1, col + 2):\n",
    "                    dist = abs(img[i, j].astype(\"int\") - mean.astype(\"int\"))\n",
    "                    if dist < threshold and not visited[i, j]:\n",
    "                       stack.append([i, j])\n",
    "                    segmented[i, j] = img[i, j]\n",
    "                    visited[i, j] = True\n",
    "    return segmented"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "0mioK0wQrR4L"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "seqm = second_segmentation(knee, 36)\n",
    "plt.imshow(seqm, cmap=\"gray\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}